{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "937a9bf7f4d02271b0e84c824f2cfec9d499b9b3c4d4ea54ebae47f399b1cd48"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tensorflow MLP\n",
    "Here we will attempt to design a regression model for noisey sin data in tensorflow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "seed_val = 2000\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "source": [
    "Generate the data and add noise to it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.1\n",
    "x = np.arange(0, 2*np.pi, timestep)\n",
    "targets = np.sin(2*x)\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "noise = np.random.normal(0,0.1,len(x))\n",
    "noisey_input = noise + x\n",
    "\n",
    "noise = np.random.normal(0,0.1,len(targets))\n",
    "noisey_targets = noise + targets\n",
    "\n",
    "dataset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "dataset[\"NoiseyX\"] = noisey_input\n",
    "dataset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "noise = np.random.normal(0,0.1,len(x))\n",
    "noisey_input = noise + x\n",
    "\n",
    "noise = np.random.normal(0,0.1,len(targets))\n",
    "noisey_targets = noise + targets\n",
    "\n",
    "testset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "testset[\"NoiseyX\"] = noisey_input\n",
    "testset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "plt.scatter(x, targets, label=\"non-noisey sin\")\n",
    "plt.scatter(testset[\"NoiseyX\"], dataset[\"NoiseyY\"], label=\"noisey sin\")\n",
    "plt.scatter(testset[\"NoiseyX\"], testset[\"NoiseyY\"], label=\"test sin\")\n",
    "plt.legend()"
   ]
  },
  {
   "source": [
    "Shuffle and split the noisey data into 60% train, 20% test and 20% valid."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(data):\n",
    "    _N1 = np.shape(data)[0]\n",
    "    _N2 = np.shape(data)[1]\n",
    "    a = -1*np.ones((_N1,_N2+1))\n",
    "    a[:,:-1] = data\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_no_bias = np.reshape(train_dataset[\"NoiseyX\"].to_numpy(), (-1,1))\n",
    "train_feat = add_bias(train_feat_no_bias)\n",
    "train_labels = np.reshape(train_dataset[\"NoiseyY\"].to_numpy(), (-1,1))\n",
    "\n",
    "test_feat_no_bias = np.reshape(testset[\"NoiseyX\"].to_numpy(), (-1,1))\n",
    "test_feat = add_bias(test_feat_no_bias)\n",
    "test_labels = np.reshape(testset[\"NoiseyY\"].to_numpy(), (-1,1))\n"
   ]
  },
  {
   "source": [
    "Here, will try tf to learn the data. \n",
    "### Note: by default, Kreas uses a bias in every layer so no need to add. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nodes = 1\n",
    "in_features = 2\n",
    "\n",
    "X = train_feat_no_bias.copy()\n",
    "Y = train_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the mlp model\n",
    "model = Sequential()\n",
    "# add the hidden layers and non-linear activation functions\n",
    "# model.add(Dense(10, input_shape=(in_features,), activation=\"sigmoid\", kernel_initializer='ones', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "\n",
    "model.add(Dense(10, input_shape=(in_features,), activation=\"tanh\"))\n",
    "model.add(Dense(5, activation='tanh'))\n",
    "# add the output layer\n",
    "model.add(Dense(out_nodes, activation=\"linear\"))\n",
    "\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\", metrics=[\"MSE\"])\n",
    "model.fit(X, Y, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_feat_no_bias\n",
    "test_output = test_labels\n",
    "\n",
    "prediction = model.predict(test_input)\n",
    "accuracy = prediction-test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.shape(test_input)[1] == 2:\n",
    "    test_input = test_input[:,0]\n",
    "\n",
    "plt.scatter(test_input, prediction)\n",
    "plt.scatter(test_input, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0,len(accuracy)),accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}