{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "937a9bf7f4d02271b0e84c824f2cfec9d499b9b3c4d4ea54ebae47f399b1cd48"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Tensorflow MLP\n",
    "Here we will attempt to design a regression model for noisey sin data in tensorflow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "seed_val = 2000\n",
    "np.random.seed(seed_val)"
   ]
  },
  {
   "source": [
    "Generate the data and add noise to it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin_data(noise_var=0.1, shuffle=False, scale=False, timestep=0.001, pi_factor=2):\n",
    "    x = np.arange(0, pi_factor*np.pi, timestep)\n",
    "    targets = np.sin(x)\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    noise = np.random.normal(0,noise_var,len(x))\n",
    "    noisey_input = noise + x\n",
    "\n",
    "    noise = np.random.normal(0,noise_var,len(targets))\n",
    "    noisey_targets = noise + targets\n",
    "\n",
    "    trainset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "    trainset[\"NoiseyX\"] = noisey_input\n",
    "    trainset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "    #_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    noise = np.random.normal(0,noise_var,len(x))\n",
    "    noisey_input = noise + x\n",
    "\n",
    "    noise = np.random.normal(0,noise_var,len(targets))\n",
    "    noisey_targets = noise + targets\n",
    "\n",
    "    testset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "    testset[\"NoiseyX\"] = noisey_input\n",
    "    testset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "    if scale:\n",
    "       trainset['NoiseyX'] = MaxAbsScaler().fit_transform(trainset['NoiseyX'].values.reshape(-1,1))\n",
    "       trainset['NoiseyY'] = MaxAbsScaler().fit_transform(trainset['NoiseyY'].values.reshape(-1,1))\n",
    "       testset['NoiseyX'] = MaxAbsScaler().fit_transform(testset['NoiseyX'].values.reshape(-1,1))\n",
    "       testset['NoiseyY'] = MaxAbsScaler().fit_transform(testset['NoiseyY'].values.reshape(-1,1))\n",
    "    #_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    plt.scatter(x, targets, label=\"non-noisey sin\", alpha=0.3)\n",
    "    plt.scatter(trainset[\"NoiseyX\"], trainset[\"NoiseyY\"], label=\"noisey sin\", marker='.')\n",
    "    plt.scatter(testset[\"NoiseyX\"], testset[\"NoiseyY\"], label=\"test sin\", marker='.')\n",
    "    plt.legend()\n",
    "\n",
    "    if shuffle:\n",
    "        return trainset.sample(frac=1), testset #testset.sample(frac=1)\n",
    "    else:\n",
    "        return trainset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_data(noise_var=0.1, shuffle=False, scale=False): \n",
    "    timestep = 0.1\n",
    "    x = np.arange(0, 2*np.pi, timestep)\n",
    "    targets = x\n",
    "\n",
    "#_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    noise = np.random.normal(0,noise_var,len(x))\n",
    "    noisey_input = noise + x\n",
    "\n",
    "    noise = np.random.normal(0,noise_var,len(targets))\n",
    "    noisey_targets = noise + targets\n",
    "\n",
    "    trainset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "    trainset[\"NoiseyX\"] = noisey_input\n",
    "    trainset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "    #_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    noise = np.random.normal(0,noise_var,len(x))\n",
    "    noisey_input = noise + x\n",
    "\n",
    "    noise = np.random.normal(0,noise_var,len(targets))\n",
    "    noisey_targets = noise + targets\n",
    "\n",
    "    testset = pd.DataFrame(columns=[\"NoiseyX\", \"NoiseyY\"])\n",
    "    testset[\"NoiseyX\"] = noisey_input\n",
    "    testset[\"NoiseyY\"] = noisey_targets\n",
    "\n",
    "    #_______________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "    plt.scatter(x, targets, label=\"non-noisey sin\", marker='.', alpha=0.3)\n",
    "    plt.scatter(trainset[\"NoiseyX\"], trainset[\"NoiseyY\"], label=\"noisey train\", marker='.')\n",
    "    plt.scatter(testset[\"NoiseyX\"], testset[\"NoiseyY\"], label=\"noisey test\", marker='.')\n",
    "    plt.legend()\n",
    "\n",
    "    if shuffle:\n",
    "        return trainset.sample(frac=1), testset.sample(frac=1)\n",
    "    else:\n",
    "        return trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(data):\n",
    "    _N1 = np.shape(data)[0]\n",
    "    _N2 = np.shape(data)[1]\n",
    "    a = -1*np.ones((_N1,_N2+1))\n",
    "    a[:,:-1] = data\n",
    "    return a"
   ]
  },
  {
   "source": [
    "Shuffle and split the noisey data into 60% train, 20% test and 20% valid."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = sin_data(0.1, shuffle=True, scale=False, pi_factor=4)\n",
    "\n",
    "print(\"training set length\", len(trainset))\n",
    "\n",
    "train_feat_no_bias = np.reshape(trainset[\"NoiseyX\"].to_numpy(), (-1,1))\n",
    "# train_feat = add_bias(train_feat_no_bias)\n",
    "train_labels = np.reshape(trainset[\"NoiseyY\"].to_numpy(), (-1,1))\n",
    "\n",
    "test_feat_no_bias = np.reshape(testset[\"NoiseyX\"].to_numpy(), (-1,1))\n",
    "# test_feat = add_bias(test_feat_no_bias)\n",
    "test_labels = np.reshape(testset[\"NoiseyY\"].to_numpy(), (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Here, will try tf to learn the data. \n",
    "### Note: by default, Kreas uses a bias in every layer so no need to add. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_nodes = 1\n",
    "in_features = 1\n",
    "\n",
    "X = train_feat_no_bias.copy()\n",
    "Y = train_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "#     initial_learning_rate=0.06,\n",
    "#     decay_steps=10000,\n",
    "#     decay_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the mlp model\n",
    "model = Sequential()\n",
    "# add the hidden layers and non-linear activation functions\n",
    "# model.add(Dense(10, input_shape=(in_features,), activation=\"sigmoid\", kernel_initializer='ones', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "# model.add(Dense(100, input_shape=(in_features,), activation=\"relu\"))\n",
    "# model.add(Dense(40, input_shape=(in_features,), activation=\"relu\"))\n",
    "# model.add(Dense(100, input_shape=(in_features,), activation=\"relu\"))\n",
    "model.add(Dense(20, activation=\"tanh\", use_bias=True))\n",
    "model.add(Dense(20, activation=\"tanh\", use_bias=True))\n",
    "# add the output layer\n",
    "model.add(Dense(out_nodes, activation=\"tanh\", use_bias=True))\n",
    "\n",
    "# optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "model.compile(loss=\"mean_absolute_error\", optimizer='SGD', metrics=[\"MSE\",\"MAE\"])\n",
    "# model.compile(loss=\"mean_absolute_error\", optimizer=keras.optimizers.Adam(0.001), metrics=[\"MSE\"])\n",
    "history = model.fit(X, Y, epochs=100, batch_size=100, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.plot(hist['epoch'], hist['MAE'], label='Train Error')\n",
    "plt.plot(hist['epoch'], hist['val_MAE'], label='Val Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_feat_no_bias\n",
    "test_output = test_labels\n",
    "\n",
    "# test_input = train_feat_no_bias\n",
    "# test_output = train_labels\n",
    "\n",
    "prediction = model.predict(test_input)\n",
    "accuracy = prediction-test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.shape(test_input)[1] == 2:\n",
    "    test_input = test_input[:,0]\n",
    "\n",
    "plt.plot(test_input, test_output, label=\"TestData\")\n",
    "plt.plot(test_input, prediction, label=\"Prediction\")\n",
    "plt.plot(test_input,accuracy, label=\"Accuracy\", alpha=0.4)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}